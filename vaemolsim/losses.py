"""
Various losses that are helpful for training VAEs.
There are two main types:
1) reconstruction losses based on the output decoder probability distribution,
   usually taking the form of a log-probability of that distribution
2) regularization losses that penalize distance of a variational encoding distribution
   from a prior distribution, usually taking the form of a KL-divergence loss
More complicated scenarios can also arise, such as requring the potential energy
when training a normalizing flow or VAE in "reverse," which is why so many
loss options appear here.
"""


import tensorflow as tf


class LogProbLoss(tf.keras.losses.Loss):
  """
  A basic loss based on the negative log-probability of a probability distribution.
  As input, it takes a training sample and a tfp.distributions object.
  """

  def __init__(self, name='log_prob_loss', **kwargs):
    """
    See tf.keras.losses.Loss for keyword arguments
    """
    super(LogProbLoss, self).__init__(name=name, **kwargs)

  def call(self, samples, decoder):
    """
    Inputs:
        samples - training samples of distribution to learn
        decoder - tfp.distributions object representing model probability density
    Outputs:
        loss - negative log-probability of x_sample under decoder, without taking average over batch;
               (returns per-sample loss)
    """
    return -decoder.log_prob(samples)

  def get_config(self):
    config = super(LogProbLoss, self).get_config()
    return config


# Same thing with the reverse ELBO reconstruction contribution
# Only trick is that if want to do both, will need different model outputs for each loss in list
# Makes sense, because will be different decoder distributions for log_prob_loss and potential_energy_log_prob_loss
# ALSO CHECK MATH
class PotentialEnergyLogProbLoss(tf.keras.losses.Loss):
  """
  A basic loss computing the potential energy of sample configurations added to the log-probability under a
  decoder model. Samples are intended (and likely) to be produced by a generative model.
  This is a key component of the reverse KL (or reverse ELBO) loss.
  """

  def __init__(self, potential, name='pot_log_prob_loss', **kwargs):
    """
    Inputs:
        potential - a potential energy function applied to generated configurations
    Outputs:
        PotentialEnergyLogProbLoss loss object
    """
    super(PotentialEnergyLogProbLoss, self).__init__(name=name, **kwargs)
    self.potential = potential

  def call(self, samples, decoder):
    """
    Inputs:
        samples - samples (configurations) generated by the model; if None, samples are drawn from the decoder
        decoder - a tfp.distributions object to compute log-probablities under the model for generated samples
    Outputs:
        loss - sum of negative log-probabilities under the true distribution (the potential energies) and model;
               each is per configuration, so the per-sample loss, not averaged or summed over batch
    """
    if samples is None:
      samples = decoder.sample()
    return self.potential(samples) - decoder.log_prob(samples)

  def get_config(self):
    config = super(PotentialEnergyLogProbLoss, self).get_config()
    config.update({"potential": self.potential,
                  })
    return config


# Consider adding another parameter to control how many samples are drawn...
# The typical behavior is to draw one sample per batch input, but there is not
# reason we cannot draw more and average over the log-probabilities computed for
# all of them
# Something like n_sample=1, etc.
class InfoRegularizer(tf.Module):
  """
  Base class for information regularization, here just setting up structure of class objects.
  Subclasses should implement a "call" method that computes the regularization loss, taking
  two distributions and samples as in:

  def call(self, dist_a, dist_b, samples):
    calculations here

  For a KL divergence, then, it is easy enough to provide a Monte Carlo estimate based on these
  distributions (and, optionally, samples from one of them). By convention, dist_a is the distribution
  that will be sampled from if samples are passed as None when calling this class. This can be
  switched by setting sample_dist to 'dist_b' instead of 'dist_a'.

  For use in VAE models, it is noteworthy that the first distribution passed to a call of a regularizer
  will be an encoder, while the second will be a prior (this follows the typical convention of computing
  the KL divergence in the forward ELBO). In these cases, it may be useful to think of the call
  signature as always satisfying (encoder, prior, samples).
  """

  def __init__(self, weight=1.0, sample_dist='dist_a', name='info_reg', **kwargs):
    """
    Inputs:
        weight - (float, 1.0) weight to scale the output of the regularizer function by (e.g., beta in beta-VAE)
        sample_dist - (str, 'dist_a') indicates which distribution sampling occurs over (can be 'dist_a' or 'dist_b')
    """
    super(InfoRegularizer, self).__init__(name=name, **kwargs)
    self.weight = tf.convert_to_tensor(weight)
    if sample_dist in ['dist_a', 'dist_b']:
      self.sample_dist = sample_dist
    else:
      raise ValueError("sample_dist must be one of 'dist_a' or 'dist_b'.")

  def __call__(self, dist_a, dist_b, samples=None):
    """
    Inputs:
        dist_a - tfp.distributions object representing a distribution (by convention the distribution where averaging is performed)
        dist_b - tfp.distributions object representing a distribution to compare to
        samples - (None) samples for computing regularization (if None, will draw from self.sample_dist)
    Outputs:
        regularization loss by calling the "call" method
    """
    if samples is None:
      if self.sample_dist == 'dist_a':
        samples = dist_a.sample()
      elif self.sample_dist == 'dist_b':
        samples = dist_b.sample()
    return self.weight * self.call(dist_a, dist_b, samples)

  def call(self, dist_a, dist_b, samples):
    raise NotImplementedError("In any subclass, a 'call' method must be implemented, taking the arguments dist_a, dist_b, samples.")


class NonRegularizer(InfoRegularizer):
  """
  A regularizer that does not apply any regularization (nothing is added to the loss):
  """

  def call(self, dist_a, dist_b, samples):
    """
    Ignores inputs and returns zero.
    """
    return 0.0


class KLDivergenceEstimate(InfoRegularizer):
  """
  Computes the KL divergence between two tfp.distributions objects.
  If a sample from the first distribution is not provided, a sample is drawn.
  """

  def call(self, dist_a, dist_b, samples):
    """
    Inputs:
        dist_a - distribution over which averaging occurs (sample is drawn)
        dist_b - distribution trying to match
        samples - samples from the dist_a distribution
    Outputs:
        loss - the Monte Carlo approximation to the KL divergence KL(dist_a, dist_b) averaged over the batch
    """
    return tf.reduce_mean(dist_a.log_prob(samples) - dist_b.log_prob(samples))


class LogProbRegularizer(InfoRegularizer):
  """
  Applies the negative log-probability of the SECOND distribution passed in to calculate a loss over input samples.
  The first distribution is ignored. This is intended to be used in the case of a deterministic encoder where the
  KL divergence diverges and should be ignored during training. In that case, we may only want to train a flow that
  defines the prior, using its negative log-probablity on the deterministically encoded samples to learn it.
  A similar strategy could be employed to train a CG model on a deterministic mapping. In that case, the "potential
  energy" function of the dist_b (prior) object would just need to be called through a log_prob method.
  """
  
  def call(self, dist_a, dist_b, samples):
    """
    Inputs:
        dist_a - the encoder distribution (will be ignored except for sampling if no samples provided)
        dist_b - the prior distribution to train (presumably as a flow or potential energy function)
        samples - samples from the (presumably deterministic) encoding to learn the distribution of via the prior
    Outputs:
        loss - the negative log-likelihood of the samples under the prior (dist_b)
    """
    return -dist_b.log_prob(samples)


class ReverseKLDivergenceEstimate(InfoRegularizer):
  """
  Computes the KL divergence IN REVERSE between two tfp.distributions objects.
  This class automatically sets sampling to be done from the prior (dist_b).
  """

  def __init__(self, **kwargs):
    super(ReverseKLDivergenceEstimate, self).__init__(**kwargs)
    self.sample_dist = 'dist_b'

  def call(self, dist_a, dist_b, samples):
    """
    Inputs:
        dist_a - distribution trying to match
        dist_b - distribution over which sampling occurs (here, the prior)
        samples - samples from the dist_b distribution
    Outputs:
        loss - the Monte Carlo approximation to the KL divergence KL(dist_b, dist_a) averaged over the batch
    """
    return tf.reduce_mean(dist_b.log_prob(samples) - dist_a.log_prob(samples))

