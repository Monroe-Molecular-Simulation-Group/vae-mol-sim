"""
Various losses that are helpful for training VAEs.

There are two main types:

1. reconstruction losses based on the output decoder probability distribution,
usually taking the form of a log-probability of that distribution
2. regularization losses that penalize distance of a variational encoding distribution
from a prior distribution, usually taking the form of a KL-divergence loss

More complicated scenarios can also arise, such as requiring the potential energy
when training a normalizing flow or VAE in "reverse," which is why so many
loss options appear here.

For regularizers, the philosophy is that each regularizer should always take two
distributions as input. From the perspective of a VAE model, these are the encoder
and the prior distributions. What we DO with those distributions is up to the type
of regularization we want to apply. This framework allows us to re-use the same
model-level code for a VAE, but change the regularizer in order to remove
regularization, or change how it is applied.
"""

import tensorflow as tf


class LogProbLoss(tf.keras.losses.Loss):
    """
  A basic loss based on the negative log-probability of a probability distribution.

  As input, it takes a training sample and a tfp.distributions object.
  """

    def __init__(self, name='log_prob_loss', **kwargs):
        """
    Creates a LogProbLoss layer instance

    See tf.keras.losses.Loss for keyword arguments
    """
        super(LogProbLoss, self).__init__(name=name, **kwargs)

    def call(self, samples, decoder):
        """
    Computes the log-probability of samples under a provided tfp.distribution object.

    Parameters
    ----------
    samples : tf.Tensor
        Training samples of distribution to learn
    decoder : tfp.distributions object
        An object representing model probability density (must have a log_prob() method).

    Returns
    -------
    loss : tf.Tensor
        Negative log-probability of samples under decoder, without taking average
        over batch (i.e, it returns the per-sample loss).
    """
        return -decoder.log_prob(samples)

    def get_config(self):
        config = super(LogProbLoss, self).get_config()
        return config


# Same thing with the reverse ELBO reconstruction contribution
# Only trick is that if want to do both, will need different model outputs for each loss in list
# Makes sense, because will be different decoder distributions for log_prob_loss and potential_energy_log_prob_loss
# ALSO CHECK MATH
class PotentialEnergyLogProbLoss(tf.keras.losses.Loss):
    """
  A basic loss combining the potential energy of sample configurations and their log-probability under a decoder.

  Samples are intended (and likely) to be produced by a generative model.
  This is a key component of the reverse KL (or reverse ELBO) loss.

  Attributes
  ----------
  potential : callable
      The potential energy function for the ensemble to learn.
  """

    def __init__(self, potential, name='pot_log_prob_loss', **kwargs):
        """
    Creates PotentialEnergyLogProbLoss instance

    Parameters
    ----------
    potential : callable
        Potential energy function applied to generated configurations
    """
        super(PotentialEnergyLogProbLoss, self).__init__(name=name, **kwargs)
        self.potential = potential

    def call(self, samples, decoder):
        """
    Computes the loss including both a potential energy and a log-probability under a decoder model.

    Parameters
    ----------
    samples : tf.Tensor
        Samples (configurations) generated by the model; if None, samples are drawn from the decoder.
    decoder : tfp.distributions object
        Distribution to compute log-probablities under the model for generated samples.

    Returns
    -------
    loss : tf.Tensor
        Sum of negative log-probabilities under the true distribution (the potential energies) and model.
        Each is per configuration, so the per-sample loss, not averaged or summed over batch.
    """
        if samples is None:
            samples = decoder.sample()
        return self.potential(samples) - decoder.log_prob(samples)

    def get_config(self):
        config = super(PotentialEnergyLogProbLoss, self).get_config()
        config.update({
            "potential": self.potential,
        })
        return config


# Consider adding another parameter to control how many samples are drawn...
# The typical behavior is to draw one sample per batch input, but there is not
# reason we cannot draw more and average over the log-probabilities computed for
# all of them
# Something like n_sample=1, etc.
class InfoRegularizer(tf.Module):
    """
  Base class for information regularization, here just setting up structure of class objects.

  Subclasses should implement a "call" method that computes the regularization loss, taking
  two distributions and samples as in:

  def call(self, dist_a, dist_b, samples):
    calculations here

  For a KL divergence, then, it is easy enough to provide a Monte Carlo estimate based on these
  distributions (and, optionally, samples from one of them). By convention, dist_a is the distribution
  that will be sampled from if samples are passed as None when calling this class. This can be
  switched by setting sample_dist to 'dist_b' instead of 'dist_a'.

  For use in VAE models, it is noteworthy that the first distribution passed to a call of a regularizer
  will be an encoder, while the second will be a prior (this follows the typical convention of computing
  the KL divergence in the forward ELBO). In these cases, it may be useful to think of the call
  signature as always satisfying (encoder, prior, samples).

  Attributes
  ----------
  weight : float
      Weight to apply to this regularization loss.
  sample_dist : str
      Distribution to sample from... either 'dist_a' or 'dist_b'.
  """

    def __init__(self, weight=1.0, sample_dist='dist_a', name='info_reg', **kwargs):
        """
    Creates InfoRegularizer instance

    Parameters
    ----------
    weight : float, default 1.0
        Weight to scale the output of the regularizer function by (e.g., beta in beta-VAE)
    sample_dist : str, default 'dist_a'
        Indicates which distribution sampling occurs over (can be 'dist_a' or 'dist_b')
    """
        super(InfoRegularizer, self).__init__(name=name, **kwargs)
        self.weight = tf.convert_to_tensor(weight, dtype=tf.float32)
        if sample_dist in ['dist_a', 'dist_b']:
            self.sample_dist = sample_dist
        else:
            raise ValueError("sample_dist must be one of 'dist_a' or 'dist_b'.")

    def __call__(self, dist_a, dist_b, samples=None):
        """
    Parameters
    ----------
    dist_a : tfp.distributions object
        Represents a distribution (by convention the distribution where averaging is performed).
    dist_b : tfp.distributions object
        Represents a distribution (by convention the distribution to compare to the reference)..
    samples : tf.Tensor, default None
        Samples for computing regularization. If None, will draw from self.sample_dist.

    Returns
    -------
    Regularization loss as the result of calling the "call" method
    """
        if samples is None:
            if self.sample_dist == 'dist_a':
                samples = dist_a.sample()
            elif self.sample_dist == 'dist_b':
                samples = dist_b.sample()
        return self.weight * self.call(dist_a, dist_b, samples)

    def call(self, dist_a, dist_b, samples):
        raise NotImplementedError(
            "In any subclass, a 'call' method must be implemented, taking the arguments dist_a, dist_b, samples.")


class NonRegularizer(InfoRegularizer):
    """
  A regularizer that does not apply any regularization (nothing is added to the loss):
  """

    def call(self, dist_a, dist_b, samples):
        """
    Ignores inputs and returns zero.

    Parameters
    ----------
    dist_a : tfp.distributions object
        Represents a distribution (by convention the distribution where averaging is performed).
    dist_b : tfp.distributions object
        Represents a distribution (by convention the distribution to compare to the reference)..
    samples : tf.Tensor (optional)
        Samples for computing regularization. If None, will draw from self.sample_dist.

    Returns
    -------
    0.0
    """
        return 0.0


class KLDivergenceEstimate(InfoRegularizer):
    """
  Computes the KL divergence between two tfp.distributions objects.

  If a sample from the first distribution is not provided, a sample is drawn.
  """

    def call(self, dist_a, dist_b, samples):
        """
    Computes the KL-divergence loss with dist_a as the reference.

    If no samples are provided, they are drawn from dist_a.

    Parameters
    ----------
    dist_a : tfp.distributions object
        Distribution over which averaging occurs (sample is drawn)
    dist_b : tfp.distributions object
        Distribution to compare to reference
    samples : tf.Tensor (optional)
        samples from the dist_a distribution

    Returns
    -------
    loss : tf.Tensor
        The Monte Carlo approximation to the KL divergence KL(dist_a, dist_b) averaged over the batch
    """
        return tf.reduce_mean(dist_a.log_prob(samples) - dist_b.log_prob(samples))


class LogProbRegularizer(InfoRegularizer):
    """
  Applies the negative log-probability of the SECOND distribution passed in to calculate a loss over input samples.

  The first distribution is ignored. This is intended to be used in the case of a deterministic encoder where the
  KL divergence diverges and should be ignored during training. In that case, we may only want to train a flow that
  defines the prior, using its negative log-probablity on the deterministically encoded samples to learn it.
  Note that if dist_a is a tfp.distributions.Deterministic distribution, no samples are necessary, as the call
  to dist_a.sample() that will occur during the __call__ method of InfoRegularizer will just return exactly the
  deterministically obtained values that defined the distribution (the "sample"). Otherwise, a sample MUST be
  provided if dist_a is set to None or a place-holder distribution object, otherwise "sampling" will not be
  performed appropriately. The intention of this regularizer is to be dropped in in place of KLDivergenceEstimate
  without modification to a model. In other words, a call to a generic regularizer in a VAE model can still
  be passed dist_a as the encoding distribution and dist_b as the prior, even if dist_a is deterministic.
  If you do use a Deterministic distribution object for dist_a, though, this will return the same thing
  as KLDivergenceEstimate. Can consider removing.

  A similar strategy as described above could be employed to train a CG model on a deterministic mapping.
  In that case, the "potential energy" function of the dist_b (prior) object would just need to be called through
  a log_prob method.
  """

    def call(self, dist_a, dist_b, samples):
        """
    Computes the loss for training only parameters in dist_b.

    Parameters
    ----------
    dist_a : tfp.distributions object
        The encoder distribution (will be ignored except for sampling if no samples provided).
    dist_b : tfp.distributions object
        The prior distribution to train (presumably as a flow or potential energy function).
    samples : tf.Tensor
        Samples from the (presumably deterministic) encoding to learn the distribution of via the prior.

    Returns
    -------
    loss : tf.Tensor
        The negative log-likelihood of the samples under the prior (dist_b).
    """
        return tf.reduce_mean(-dist_b.log_prob(samples))


class ReverseKLDivergenceEstimate(InfoRegularizer):
    """
  Computes the KL divergence IN REVERSE between two tfp.distributions objects.

  This class automatically sets sampling to be done from the prior (dist_b).
  """

    def __init__(self, **kwargs):
        super(ReverseKLDivergenceEstimate, self).__init__(**kwargs)
        self.sample_dist = 'dist_b'

    def call(self, dist_a, dist_b, samples):
        """
    Computes the KL-divergence loss with dist_b as the reference.

    If no samples are provided, they are drawn from dist_b.

    Parameters
    ----------
    dist_a : tfp.distributions object
        Distribution to compare to reference
    dist_b : tfp.distributions object
        Distribution over which averaging occurs (sample is drawn)
    samples : tf.Tensor (optional)
        samples from the dist_b distribution

    Returns
    -------
    loss : tf.Tensor
        The Monte Carlo approximation to the KL divergence KL(dist_b, dist_a) averaged over the batch
    """
        return tf.reduce_mean(dist_b.log_prob(samples) - dist_a.log_prob(samples))
